# -*- coding: utf-8 -*-
"""Whatsapp_project (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uD0ldaJ2CjIvxhf7RHAVAr554lTow1Hm

**EMOJI** **INSTALLATION**
"""

!pip install emojis

"""**IMPORTING** **LIBRARIES**"""

import re
import regex
import pandas as pd
import numpy as np
import emojis
import plotly.express as px
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

"""**SOURCE CODE FOR DATETIME AND AUTHOR AND MESSAGE**"""

def date_time(s):
    pattern = '^([0-9]+)(\/)([0-9]+)(\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'
    result = regex.match(pattern, s)
    if result:
        return True
    return False

def find_author(s):
    s = s.split(":")
    if len(s)==2:
        return True
    else:
        return False
def getDatapoint(line):
    splitline = line.split(' - ')
    dateTime = splitline[0]
    date, time = dateTime.split(", ")
    message = " ".join(splitline[1:])
    if find_author(message):
        splitmessage = message.split(": ")
        author = splitmessage[0]
        message = " ".join(splitmessage[1:])
    else:
        author= None
    return date, time, author, message

"""**SOURCE** **CODE** **FOR** **WHATSAPP** **CHAT** **ANALYSIS**"""

data = []
conversation = 'vaishu.txt'
with open(conversation, encoding="utf-8") as fp:
    fp.readline()
    messageBuffer = []
    date, time, author = None, None, None
    while True:
        line = fp.readline()
        if not line:
            break
        line = line.strip()
        if date_time(line):
            if len(messageBuffer) > 0:
                data.append([date, time, author, ' '.join(messageBuffer)])
            messageBuffer.clear()
            date, time, author, message = getDatapoint(line)
            messageBuffer.append(message)
        else:
            messageBuffer.append(line)

"""**PANDAS DATAFRAMES**"""

df = pd.DataFrame(data, columns=["Date", 'Time', 'Author', 'Message'])
df['Date'] = pd.to_datetime(df['Date'])

"""**OUTPUT**"""

print(df.head(31600))

"""**EMOJIS**"""

def split_count(text):
  emoji_list=[]
  data=emojis.get(str(text))
  return data

df["Emoji"] = df["Message"].apply(split_count)

image_messages_df = df[df["Message"] == '<‎image omitted>']
message_df=df.drop(image_messages_df.index)
print(image_messages_df)

video_messages_df = df[df["Message"] == '<‎video omitted>']
message_df=df.drop(video_messages_df.index)
print(video_messages_df)

gif_messages_df = df[df["Message"] == '<‎GIF omitted>']
message_df=df.drop(gif_messages_df.index)
print(gif_messages_df)

message_df["Date"] = pd.to_datetime(message_df.Date)

message_df["Time"] = pd.to_datetime(message_df.Time).dt.strftime('%H:%M')

"""**DATAFRAMES FOR ALL ATTRIBUTES**"""

message_df.head(31600)

"""**TOTAL NO OF EMOJIS SENT**"""

total_emojis_list=list(set([a for b in message_df.Emoji for a in b]))
total_emojis = len(total_emojis_list)
print(total_emojis)

"""**VISUALIZATION OF EMOJIS**"""

total_emojis_list = list(set([a for b in message_df.Emoji for a in b]))
total_emojis = len(total_emojis_list)

total_emojis_list = list([a for b in message_df.Emoji for a in b])
emoji_dict = dict(Counter(total_emojis_list))
emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)
for i in emoji_dict:
  print(i)
  
emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])
import plotly.express as px
fig = px.pie(emoji_df, values='count', names='emoji')
fig.update_traces(textposition='inside', textinfo='percent+label')
fig.show()

"""**TOTAL MESSAGES IN THE CHAT**"""

total_messages = df.shape[0]
print(total_messages)

"""**TOTAL MEDIA MESSAGES**"""

media_messages = df[df["Message"]=='<Media omitted>'].shape[0]
print(media_messages)

"""**TOTAL LINKS,MESSAGES,MEDIA**"""

URLPATTERN = r'(https?://\S+)'
df['urlcount'] = df.Message.apply(lambda x: regex.findall(URLPATTERN, x)).str.len()
links = np.sum(df.urlcount)

print("Chats between vaishu and sowmya")
print("Total Messages: ", total_messages)
print("Number of Media Shared: ", media_messages)
print("Number of emojis sent:",total_emojis)
print("Number of Links Shared", links)

media_messages_df = df[df['Message'] == '<Media omitted>']

messages_df = df.drop(media_messages_df.index)

"""**LETTER,WORD,MESSAGE COUNT**"""

messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))
messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))
messages_df["MessageCount"]=1

"""**PANDAS DATAFRAMES FOR ALL ATTRIBUTES**"""

messages_df.head(31600)

"""**ATTRIBUTES**"""

messages_df.info()

"""**CONVERTING DATA TO EXCEL FILE**"""

df.to_csv('chat.csv')

"""**CHAT ANALYSIS IN WEEKDAYS**"""

def f(i):
  l = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
  return l[i];
day_df=pd.DataFrame(messages_df["Message"])
day_df['day_of_date'] = messages_df['Date'].dt.weekday
day_df['day_of_date'] = day_df["day_of_date"].apply(f)
day_df["messagecount"] = 1
day = day_df.groupby("day_of_date").sum()
day.reset_index(inplace=True)
print(day_df)

"""**VISUALIZATION OF WEEKDAYS in polar gragh** 



"""

fig = px.line_polar(day, r='messagecount', theta='day_of_date', line_close=True)
fig.update_traces(fill='toself')
fig.update_layout(
  polar=dict(
    radialaxis=dict(
      visible=True,
    )),
  showlegend=False
)
fig.show()

"""**VISUALIZATION OF MESSAGECOUNT IN YEAR in XAXES GRAPH   **"""

date_df = messages_df.groupby("Date").sum()
date_df.reset_index(inplace=True)
fig = px.line(date_df, x="Date", y="MessageCount")
fig.update_xaxes(nticks=20)
fig.show()

"""**MOST ACTIVE PERSON IN THE CHAT**




"""

plt.figure(figsize=(9,6))
mostly_active = df['Author'].value_counts() 
m_a = mostly_active.head(2)
bars = ['vaishu','sowmya']
x_pos = np.arange(len(bars))
m_a.plot.bar()
plt.xlabel('Authors',fontdict={'fontsize': 14,'fontweight': 10})
plt.ylabel('No. of messages',fontdict={'fontsize': 14,'fontweight': 10})
plt.title('Mostly active member of chat',fontdict={'fontsize': 20,'fontweight': 8})
plt.xticks(x_pos, bars)
plt.show()

"""**WORDS USED SO MANY TIMES**"""

text = " ".join(review for review in messages_df.Message)
print ("There are {} words in all the messages.".format(len(text)))
stopwords = set(STOPWORDS)
# Generate a word cloud image
wordcloud = WordCloud(stopwords=stopwords, background_color="white").generate(text)
# Display the generated image:
# the matplotlib way:
plt.figure( figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

"""**VISUALIZATION OF ACTIVE AUTHOR**"""

auth = messages_df.groupby("Author").sum()
auth.reset_index(inplace=True)
fig = px.bar(auth, y="Author", x="MessageCount", color='Author', orientation="h",
             color_discrete_sequence=["red", "green"],
             title="Explicit color sequence"
            )

fig.show()

"""**AUTHOR INFORMATION**"""

media_messages_df = df[df['Message'] == '<Media omitted>']
messages_df = df.drop(media_messages_df.index)
messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))
messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))
messages_df["MessageCount"]=1

l = ["Vaishu", "Sowmya"]
for i in range(len(l)):
  # Filtering out messages of particular user
  req_df= messages_df[messages_df["Author"] == l[i]]
  # req_df will contain messages of only one particular user
  print(f'Stats of {l[i]} -')
  # shape will print number of rows which indirectly means the number of messages
  print('Messages Sent', req_df.shape[0])
  #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message
  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]
  print('Average Words per message', words_per_message)
  #media conists of media messages
  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]
  print('Media Messages Sent', media)
  #emojis conists of total emojis
  total_emojis_list=list(set([a for b in message_df.Emoji for a in b]))
  total_emojis = len(total_emojis_list)
  print('total emojis sent',total_emojis)
  #links consist of total links
  links = sum(req_df["urlcount"])   
  print('Links Sent', links)